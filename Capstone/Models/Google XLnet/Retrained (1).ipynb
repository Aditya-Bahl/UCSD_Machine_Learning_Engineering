{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_data.csv', names =['label', 'headline'], encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.6.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.0.43)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.1.91)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.18.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.25.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.51.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2020.11.13)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.17.71)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch-transformers) (0.18.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2020.11.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests->pytorch-transformers) (2.6)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.26.2)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.4.2)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.71 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.20.71)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.21.0,>=1.20.71->boto3->pytorch-transformers) (2.8.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.3.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.25.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (2.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.26.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-transformers\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.5.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.5.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.3.4)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\n",
    "from transformers import AdamW\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quadro P5000'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "sentences = df.headline.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "sentences = [sentence + \" [SEP] [CLS]\" for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "df['label'] =df['label'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "print(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2], dtype=int8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing . [SEP] [CLS]'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0c68daa4eb4c8690a8903bd895e461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=798011.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenize the first sentence:\n",
      "['▁according', '▁to', '▁', 'gran', '▁', ',', '▁the', '▁company', '▁has', '▁no', '▁plans', '▁to', '▁move', '▁all', '▁production', '▁to', '▁', 'rus', 'sia', '▁', ',', '▁although', '▁that', '▁is', '▁where', '▁the', '▁company', '▁is', '▁growing', '▁', '.', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print (\"Tokenize the first sentence:\")\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#Use train_test_split to split our data into train and validation sets for training\n",
    "\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=56, test_size=0.2)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=56, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs, dtype=torch.long)\n",
    "validation_inputs = torch.tensor(validation_inputs, dtype=torch.long)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "validation_labels = torch.tensor(validation_labels, dtype=torch.long)\n",
    "train_masks = torch.tensor(train_masks, dtype=torch.long)\n",
    "validation_masks = torch.tensor(validation_masks, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Select a batch size for training. For fine-tuning with XLNet, the authors recommend a batch size of 32, 48, or 128. We will use 32 here to avoid memory issues.\n",
    "batch_size = 64\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54884c5d4354541878deceae9965561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=760.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9720e4469339476c81f43574af6e378e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=467042463.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLNetForSequenceClassification(\n",
       "  (transformer): XLNetModel(\n",
       "    (word_embedding): Embedding(32000, 768)\n",
       "    (layer): ModuleList(\n",
       "      (0): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (8): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (9): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (10): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (11): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (sequence_summary): SequenceSummary(\n",
       "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (first_dropout): Identity()\n",
       "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (logits_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load XLNEtForSequenceClassification, the pretrained XLNet model with a single linear classification layer on top. \n",
    "\n",
    "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=3)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# This variable contains all of the hyperparemeter information our training loop needs\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                     lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 1/2 [01:28<01:28, 88.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7811405824833229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 2/2 [02:56<00:00, 88.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3662260563158598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Store our loss and accuracy for plotting\n",
    "train_loss_set = []\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 2\n",
    "\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "  \n",
    "  \n",
    "  # Training\n",
    "  \n",
    "  # Set our model to training mode (as opposed to evaluation mode)\n",
    "  model.train()\n",
    "  \n",
    "  # Tracking variables\n",
    "  tr_loss = 0\n",
    "  nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "  # Train the data for one epoch\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # Clear out the gradients (by default they accumulate)\n",
    "    optimizer.zero_grad()\n",
    "    #print(b_labels)\n",
    "    # Forward pass\n",
    "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "    loss = outputs[0]\n",
    "    logits = outputs[1]\n",
    "    train_loss_set.append(loss.item())    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update parameters and take a step using the computed gradient\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    # Update tracking variables\n",
    "    tr_loss += loss.item()\n",
    "    nb_tr_examples += b_input_ids.size(0)\n",
    "    nb_tr_steps += 1\n",
    "\n",
    "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    \n",
    "    \n",
    "#   # Validation\n",
    "\n",
    "#   # Put model in evaluation mode to evaluate loss on the validation set\n",
    "#   model.eval()\n",
    "\n",
    "#   # Tracking variables \n",
    "#   eval_loss, eval_accuracy = 0, 0\n",
    "#   nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "#   # Evaluate data for one epoch\n",
    "#   for batch in validation_dataloader:\n",
    "#     # Add batch to GPU\n",
    "#     batch = tuple(t.to(device) for t in batch)\n",
    "#     # Unpack the inputs from our dataloader\n",
    "#     b_input_ids, b_input_mask, b_labels = batch\n",
    "#     # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "#     with torch.no_grad():\n",
    "#       # Forward pass, calculate logit predictions\n",
    "#       output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "#       logits = output[0]\n",
    "    \n",
    "#     # Move logits and labels to CPU\n",
    "#     logits = logits.detach().cpu().numpy()\n",
    "#     label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "#     tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "#     eval_accuracy += tmp_eval_accuracy\n",
    "#     nb_eval_steps += 1\n",
    "\n",
    "#   print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "directory_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'model_with_retraining.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), directory_path+'/model_without_language_model.ckpt')\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_predict = []\n",
    "    y_true_ = []\n",
    "    for i, batch in enumerate(validation_dataloader):\n",
    "      batch = tuple(t.to(device) for t in batch)\n",
    "      # Unpack the inputs from our dataloader\n",
    "      b_input_ids, b_input_mask, b_labels = batch\n",
    "      # Forward pass\n",
    "      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "      # print (outputs)\n",
    "      prediction = torch.argmax(outputs[0],dim=1)\n",
    "      total += b_labels.size(0)\n",
    "      correct+=(prediction==b_labels).sum().item()\n",
    "    \n",
    "      y_predict.append(prediction)\n",
    "      y_true_.append(b_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on vla data is: 85.97938144329896 %\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy of the model on vla data is: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "y_pred = [item for sublist in y_predict for item in sublist]\n",
    "y_true = [item for sublist in y_true_ for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "y_pred = [x.cpu().numpy() for x in y_pred]\n",
    "y_true = [x.cpu().numpy() for x in y_true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.75      0.81       116\n",
      "     neutral       0.87      0.92      0.89       580\n",
      "    positive       0.83      0.78      0.80       274\n",
      "\n",
      "    accuracy                           0.86       970\n",
      "   macro avg       0.86      0.82      0.84       970\n",
      "weighted avg       0.86      0.86      0.86       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['negative', 'neutral', 'positive']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 87,  21,   8],\n",
       "       [ 11, 534,  35],\n",
       "       [  1,  60, 213]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df_cm = pd.DataFrame(cm, target_names, target_names)\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True, fmt='d') # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
