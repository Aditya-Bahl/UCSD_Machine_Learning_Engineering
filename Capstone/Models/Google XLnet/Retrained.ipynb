{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_data.csv', names =['label', 'headline'], encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.18.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.51.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.1.91)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.17.71)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.6.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2020.11.13)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.0.43)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.25.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.71 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.20.71)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.4.2)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch-transformers) (0.18.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.17.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests->pytorch-transformers) (2.6)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.26.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2020.11.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.21.0,>=1.20.71->boto3->pytorch-transformers) (2.8.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.5.1)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.13.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.26.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-transformers\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.3.4)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\n",
    "from transformers import AdamW\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quadro P6000'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "sentences = df.headline.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "sentences = [sentence + \" [SEP] [CLS]\" for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "df['label'] =df['label'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "print(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2], dtype=int8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing . [SEP] [CLS]'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize the first sentence:\n",
      "['▁according', '▁to', '▁', 'gran', '▁', ',', '▁the', '▁company', '▁has', '▁no', '▁plans', '▁to', '▁move', '▁all', '▁production', '▁to', '▁', 'rus', 'sia', '▁', ',', '▁although', '▁that', '▁is', '▁where', '▁the', '▁company', '▁is', '▁growing', '▁', '.', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print (\"Tokenize the first sentence:\")\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#Use train_test_split to split our data into train and validation sets for training\n",
    "\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=56, test_size=0.2)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=56, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs, dtype=torch.long)\n",
    "validation_inputs = torch.tensor(validation_inputs, dtype=torch.long)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "validation_labels = torch.tensor(validation_labels, dtype=torch.long)\n",
    "train_masks = torch.tensor(train_masks, dtype=torch.long)\n",
    "validation_masks = torch.tensor(validation_masks, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Select a batch size for training. For fine-tuning with XLNet, the authors recommend a batch size of 32, 48, or 128. We will use 32 here to avoid memory issues.\n",
    "batch_size = 64\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLNetForSequenceClassification(\n",
       "  (transformer): XLNetModel(\n",
       "    (word_embedding): Embedding(32000, 768)\n",
       "    (layer): ModuleList(\n",
       "      (0): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (8): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (9): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (10): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (11): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (sequence_summary): SequenceSummary(\n",
       "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (first_dropout): Identity()\n",
       "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (logits_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load XLNEtForSequenceClassification, the pretrained XLNet model with a single linear classification layer on top. \n",
    "\n",
    "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=3)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# This variable contains all of the hyperparemeter information our training loop needs\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                     lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 1/2 [01:00<01:00, 60.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.839116922167481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 2/2 [02:00<00:00, 60.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.42247652250235196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Store our loss and accuracy for plotting\n",
    "train_loss_set = []\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 2\n",
    "\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "  \n",
    "  \n",
    "  # Training\n",
    "  \n",
    "  # Set our model to training mode (as opposed to evaluation mode)\n",
    "  model.train()\n",
    "  \n",
    "  # Tracking variables\n",
    "  tr_loss = 0\n",
    "  nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "  # Train the data for one epoch\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # Clear out the gradients (by default they accumulate)\n",
    "    optimizer.zero_grad()\n",
    "    #print(b_labels)\n",
    "    # Forward pass\n",
    "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "    loss = outputs[0]\n",
    "    logits = outputs[1]\n",
    "    train_loss_set.append(loss.item())    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update parameters and take a step using the computed gradient\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    # Update tracking variables\n",
    "    tr_loss += loss.item()\n",
    "    nb_tr_examples += b_input_ids.size(0)\n",
    "    nb_tr_steps += 1\n",
    "\n",
    "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    \n",
    "    \n",
    "#   # Validation\n",
    "\n",
    "#   # Put model in evaluation mode to evaluate loss on the validation set\n",
    "#   model.eval()\n",
    "\n",
    "#   # Tracking variables \n",
    "#   eval_loss, eval_accuracy = 0, 0\n",
    "#   nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "#   # Evaluate data for one epoch\n",
    "#   for batch in validation_dataloader:\n",
    "#     # Add batch to GPU\n",
    "#     batch = tuple(t.to(device) for t in batch)\n",
    "#     # Unpack the inputs from our dataloader\n",
    "#     b_input_ids, b_input_mask, b_labels = batch\n",
    "#     # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "#     with torch.no_grad():\n",
    "#       # Forward pass, calculate logit predictions\n",
    "#       output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "#       logits = output[0]\n",
    "    \n",
    "#     # Move logits and labels to CPU\n",
    "#     logits = logits.detach().cpu().numpy()\n",
    "#     label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "#     tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "#     eval_accuracy += tmp_eval_accuracy\n",
    "#     nb_eval_steps += 1\n",
    "\n",
    "#   print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "directory_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), directory_path+'/model_with_retraining.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), directory_path+'/model_without_language_model.ckpt')\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_predict = []\n",
    "    y_true_ = []\n",
    "    for i, batch in enumerate(validation_dataloader):\n",
    "      batch = tuple(t.to(device) for t in batch)\n",
    "      # Unpack the inputs from our dataloader\n",
    "      b_input_ids, b_input_mask, b_labels = batch\n",
    "      # Forward pass\n",
    "      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "      # print (outputs)\n",
    "      prediction = torch.argmax(outputs[0],dim=1)\n",
    "      total += b_labels.size(0)\n",
    "      correct+=(prediction==b_labels).sum().item()\n",
    "    \n",
    "      y_predict.append(prediction)\n",
    "      y_true_.append(b_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on vla data is: 84.02061855670104 %\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy of the model on vla data is: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "y_pred = [item for sublist in y_predict for item in sublist]\n",
    "y_true = [item for sublist in y_true_ for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "y_pred = [x.cpu().numpy() for x in y_pred]\n",
    "y_true = [x.cpu().numpy() for x in y_true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.87      0.81       116\n",
      "     neutral       0.84      0.93      0.88       580\n",
      "    positive       0.91      0.63      0.74       274\n",
      "\n",
      "    accuracy                           0.84       970\n",
      "   macro avg       0.84      0.81      0.81       970\n",
      "weighted avg       0.85      0.84      0.83       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['negative', 'neutral', 'positive']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101,  10,   5],\n",
       "       [ 27, 542,  11],\n",
       "       [  5,  97, 172]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df_cm = pd.DataFrame(cm, target_names, target_names)\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True, fmt='d') # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
